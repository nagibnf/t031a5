#!/usr/bin/env python3
"""
Script de teste para os provedores LLM reais do sistema t031a5.

Testa OpenAI e Anthropic providers.
"""

import sys
import asyncio
import logging
from pathlib import Path

# Adiciona o diretÃ³rio src ao path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from t031a5.llm.provider import LLMProvider
from t031a5.fuser.base import FusedData

# Configura logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


async def test_openai_provider():
    """Testa o provedor OpenAI."""
    
    print("ğŸ¤– Testando OpenAI Provider")
    print("=" * 50)
    
    try:
        # ConfiguraÃ§Ã£o do OpenAI
        config = {
            "provider": "openai",
            "model": "gpt-4o-mini",
            "temperature": 0.7,
            "max_tokens": 200,
            "timeout": 30.0,
            "api_key": "YOUR_OPENAI_API_KEY_HERE",  # Substitua pela sua API key
            "requests_per_minute": 60,
            "include_sensors": True,
            "include_location": True,
            "include_robot_state": True,
            "fallback_provider": "mock"
        }
        
        # Cria o provider
        provider = LLMProvider(config)
        
        # Inicializa
        print("1. Inicializando OpenAI Provider...")
        success = await provider.initialize()
        
        if not success:
            print("âŒ Falha na inicializaÃ§Ã£o do OpenAI Provider")
            print("   Verifique se a API key estÃ¡ configurada corretamente")
            return False
        
        print("âœ… OpenAI Provider inicializado com sucesso")
        
        # Testa processamento
        print("\n2. Testando processamento...")
        
        # Dados simulados
        fused_data = FusedData(
            content="OlÃ¡! Como vocÃª estÃ¡ hoje?",
            confidence=0.9,
            source="voice",
            timestamp=1234567890.0,
            metadata={
                "sensors": {
                    "battery": 85,
                    "temperature": 25.5,
                    "status": "normal"
                },
                "gps": {
                    "latitude": -23.5505,
                    "longitude": -46.6333,
                    "accuracy": 5.0
                },
                "robot_state": {
                    "posture": "standing",
                    "movement": "idle",
                    "arms": "neutral"
                }
            }
        )
        
        system_prompt = "VocÃª Ã© um assistente robÃ³tico humanÃ³ide G1 da Unitree. Responda sempre em portuguÃªs brasileiro de forma natural e conversacional."
        
        # Processa
        response = await provider.process(fused_data, system_prompt)
        
        if response:
            print("âœ… Resposta recebida do OpenAI:")
            print(f"   Modelo: {response.model}")
            print(f"   Provedor: {response.provider}")
            print(f"   Tokens usados: {response.tokens_used}")
            print(f"   ConteÃºdo: {response.content[:100]}...")
            print(f"   Metadata: {response.metadata}")
        else:
            print("âŒ Nenhuma resposta recebida do OpenAI")
            return False
        
        # Para o provider
        await provider.stop()
        print("\nâœ… OpenAI Provider testado com sucesso!")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro no teste do OpenAI Provider: {e}")
        return False


async def test_anthropic_provider():
    """Testa o provedor Anthropic."""
    
    print("\nğŸ¤– Testando Anthropic Provider")
    print("=" * 50)
    
    try:
        # ConfiguraÃ§Ã£o do Anthropic
        config = {
            "provider": "anthropic",
            "model": "claude-3-5-sonnet-20241022",
            "temperature": 0.7,
            "max_tokens": 200,
            "timeout": 30.0,
            "api_key": "YOUR_ANTHROPIC_API_KEY_HERE",  # Substitua pela sua API key
            "requests_per_minute": 60,
            "include_sensors": True,
            "include_location": True,
            "include_robot_state": True,
            "fallback_provider": "mock"
        }
        
        # Cria o provider
        provider = LLMProvider(config)
        
        # Inicializa
        print("1. Inicializando Anthropic Provider...")
        success = await provider.initialize()
        
        if not success:
            print("âŒ Falha na inicializaÃ§Ã£o do Anthropic Provider")
            print("   Verifique se a API key estÃ¡ configurada corretamente")
            return False
        
        print("âœ… Anthropic Provider inicializado com sucesso")
        
        # Testa processamento
        print("\n2. Testando processamento...")
        
        # Dados simulados
        fused_data = FusedData(
            content="Qual Ã© a sua opiniÃ£o sobre robÃ³tica humanÃ³ide?",
            confidence=0.9,
            source="voice",
            timestamp=1234567890.0,
            metadata={
                "sensors": {
                    "battery": 90,
                    "temperature": 24.0,
                    "status": "excellent"
                },
                "gps": {
                    "latitude": -23.5505,
                    "longitude": -46.6333,
                    "accuracy": 3.0
                },
                "robot_state": {
                    "posture": "sitting",
                    "movement": "conversing",
                    "arms": "gesturing"
                }
            }
        )
        
        system_prompt = "VocÃª Ã© um assistente robÃ³tico humanÃ³ide G1 da Unitree. Responda sempre em portuguÃªs brasileiro de forma natural e conversacional."
        
        # Processa
        response = await provider.process(fused_data, system_prompt)
        
        if response:
            print("âœ… Resposta recebida do Anthropic:")
            print(f"   Modelo: {response.model}")
            print(f"   Provedor: {response.provider}")
            print(f"   Tokens usados: {response.tokens_used}")
            print(f"   ConteÃºdo: {response.content[:100]}...")
            print(f"   Metadata: {response.metadata}")
        else:
            print("âŒ Nenhuma resposta recebida do Anthropic")
            return False
        
        # Para o provider
        await provider.stop()
        print("\nâœ… Anthropic Provider testado com sucesso!")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro no teste do Anthropic Provider: {e}")
        return False


async def test_fallback_mechanism():
    """Testa o mecanismo de fallback."""
    
    print("\nğŸ”„ Testando Mecanismo de Fallback")
    print("=" * 50)
    
    try:
        # ConfiguraÃ§Ã£o com provedor inexistente (deve usar fallback)
        config = {
            "provider": "nonexistent_provider",
            "model": "gpt-4o-mini",
            "temperature": 0.7,
            "max_tokens": 200,
            "timeout": 30.0,
            "fallback_provider": "mock"
        }
        
        # Cria o provider
        provider = LLMProvider(config)
        
        # Inicializa
        print("1. Inicializando Provider com fallback...")
        success = await provider.initialize()
        
        if not success:
            print("âŒ Falha na inicializaÃ§Ã£o do Provider")
            return False
        
        print("âœ… Provider inicializado com sucesso (usando fallback)")
        
        # Testa processamento
        print("\n2. Testando processamento com fallback...")
        
        # Dados simulados
        fused_data = FusedData(
            content="Teste de fallback",
            confidence=0.8,
            source="test",
            timestamp=1234567890.0,
            metadata={}
        )
        
        system_prompt = "VocÃª Ã© um assistente de teste."
        
        # Processa
        response = await provider.process(fused_data, system_prompt)
        
        if response:
            print("âœ… Resposta recebida do fallback:")
            print(f"   Modelo: {response.model}")
            print(f"   Provedor: {response.provider}")
            print(f"   ConteÃºdo: {response.content[:100]}...")
        else:
            print("âŒ Nenhuma resposta recebida do fallback")
            return False
        
        # Para o provider
        await provider.stop()
        print("\nâœ… Mecanismo de Fallback testado com sucesso!")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro no teste do Fallback: {e}")
        return False


async def test_provider_status():
    """Testa o status dos provedores."""
    
    print("\nğŸ“Š Testando Status dos Provedores")
    print("=" * 50)
    
    try:
        # Testa status do Mock Provider
        config = {
            "provider": "mock",
            "model": "mock-g1",
            "temperature": 0.7,
            "max_tokens": 200,
            "response_delay": 0.1,
            "error_rate": 0.0
        }
        
        provider = LLMProvider(config)
        await provider.initialize()
        
        print("1. Status do Mock Provider:")
        status = await provider.get_status()
        print(f"   Inicializado: {status['initialized']}")
        print(f"   Provedor: {status['provider_type']}")
        print(f"   Modelo: {status['model']}")
        print(f"   MÃ©tricas: {status['metrics']}")
        
        await provider.stop()
        
        print("\nâœ… Status dos Provedores testado com sucesso!")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro no teste de Status: {e}")
        return False


if __name__ == "__main__":
    async def main():
        print("ğŸš€ Iniciando testes dos Provedores LLM Reais\n")
        
        results = []
        
        # Teste de status (sempre funciona)
        print("Teste 1: Status dos Provedores")
        results.append(await test_provider_status())
        
        # Teste de fallback (sempre funciona)
        print("\nTeste 2: Mecanismo de Fallback")
        results.append(await test_fallback_mechanism())
        
        # Testes dos provedores reais (requerem API keys)
        print("\nTeste 3: OpenAI Provider")
        print("âš ï¸  Requer API key do OpenAI configurada")
        results.append(await test_openai_provider())
        
        print("\nTeste 4: Anthropic Provider")
        print("âš ï¸  Requer API key do Anthropic configurada")
        results.append(await test_anthropic_provider())
        
        # Resultado final
        print("\n" + "="*60)
        print("ğŸ“Š RESULTADO FINAL DOS TESTES")
        print("="*60)
        
        # Filtra valores None e conta sucessos
        valid_results = [r for r in results if r is not None]
        passed = sum(valid_results)
        total = len(valid_results)
        
        print(f"Testes passaram: {passed}/{total}")
        
        if passed >= 2:  # Pelo menos status e fallback devem funcionar
            print("ğŸ‰ TESTES BÃSICOS PASSARAM!")
            print("Os provedores LLM estÃ£o funcionando corretamente!")
            
            if passed < total:
                print("\nğŸ’¡ Para usar provedores reais:")
                print("   1. Configure suas API keys nos arquivos de configuraÃ§Ã£o")
                print("   2. Execute: pip install openai anthropic")
                print("   3. Teste novamente")
        else:
            print("âŒ Alguns testes bÃ¡sicos falharam")
        
        return passed >= 2
    
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
