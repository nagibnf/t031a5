#!/usr/bin/env python3
"""
Script de setup para Ollama no sistema t031a5
Configura Ollama para uso com o rob√¥ Tobias (G1)
"""

import os
import sys
import subprocess
import platform
from pathlib import Path

def print_header():
    print("üöÄ SETUP OLLAMA - Sistema t031a5")
    print("=" * 50)
    print("Configurando Ollama para Tobias (G1)")
    print()

def check_system():
    """Verifica o sistema operacional"""
    system = platform.system()
    arch = platform.machine()
    
    print(f"üñ•Ô∏è Sistema: {system}")
    print(f"üèóÔ∏è Arquitetura: {arch}")
    
    if system == "Linux" and "aarch64" in arch:
        print("‚úÖ Jetson detectado!")
        return "jetson"
    elif system == "Darwin":
        print("‚úÖ macOS detectado!")
        return "macos"
    else:
        print("‚ö†Ô∏è Sistema n√£o identificado")
        return "unknown"

def install_ollama(system_type):
    """Instala Ollama baseado no sistema"""
    print("\nüì• Instalando Ollama...")
    
    if system_type == "jetson":
        # Jetson Orin NX - ARM64
        install_cmd = "curl -fsSL https://ollama.ai/install.sh | sh"
    elif system_type == "macos":
        # macOS
        install_cmd = "curl -fsSL https://ollama.ai/install.sh | sh"
    else:
        print("‚ùå Sistema n√£o suportado")
        return False
    
    try:
        print(f"üîß Executando: {install_cmd}")
        result = subprocess.run(install_cmd, shell=True, capture_output=True, text=True)
        
        if result.returncode == 0:
            print("‚úÖ Ollama instalado com sucesso!")
            return True
        else:
            print(f"‚ùå Erro na instala√ß√£o: {result.stderr}")
            return False
    except Exception as e:
        print(f"‚ùå Erro: {e}")
        return False

def start_ollama_service():
    """Inicia o servi√ßo Ollama"""
    print("\nüîß Iniciando servi√ßo Ollama...")
    
    try:
        # Tenta iniciar o servi√ßo
        result = subprocess.run(["ollama", "serve"], 
                              capture_output=True, 
                              text=True, 
                              timeout=5)
        
        if result.returncode == 0:
            print("‚úÖ Servi√ßo Ollama iniciado!")
            return True
        else:
            print("‚ö†Ô∏è Servi√ßo j√° pode estar rodando")
            return True
            
    except subprocess.TimeoutExpired:
        print("‚úÖ Servi√ßo Ollama iniciado em background")
        return True
    except Exception as e:
        print(f"‚ùå Erro ao iniciar servi√ßo: {e}")
        return False

def download_models():
    """Baixa modelos principais"""
    print("\nüì• Baixando modelos principais...")
    
    models = [
        "llama3.1:8b",      # Modelo principal
        "mistral:7b",       # Alternativa r√°pida
    ]
    
    for model in models:
        print(f"üì• Baixando {model}...")
        try:
            result = subprocess.run(["ollama", "pull", model], 
                                  capture_output=True, 
                                  text=True)
            
            if result.returncode == 0:
                print(f"‚úÖ {model} baixado com sucesso!")
            else:
                print(f"‚ùå Erro ao baixar {model}: {result.stderr}")
                
        except Exception as e:
            print(f"‚ùå Erro: {e}")

def create_config_files():
    """Cria arquivos de configura√ß√£o"""
    print("\n‚öôÔ∏è Criando configura√ß√µes...")
    
    # Verifica se os arquivos j√° existem
    config_files = [
        "config/g1_ollama_llm.json5",
        "src/t031a5/llm/ollama_manager.py"
    ]
    
    for config_file in config_files:
        if Path(config_file).exists():
            print(f"‚úÖ {config_file} j√° existe")
        else:
            print(f"‚ùå {config_file} n√£o encontrado")

def create_test_script():
    """Cria script de teste"""
    test_script = """#!/usr/bin/env python3
import asyncio
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
from t031a5.llm.ollama_manager import OllamaManager

async def test_ollama():
    manager = OllamaManager()
    if await manager.initialize():
        print("‚úÖ Ollama inicializado")
        
        print("\\nüìä Testando performance...")
        results = await manager.test_performance()
        
        print("\\nüìã RESULTADOS")
        if results["ollama"]["success"]:
            print(f"üñ•Ô∏è Ollama: {results['ollama']['time']:.2f}s")
            print(f"   Resposta: {results['ollama']['response']}")
        else:
            print("‚ùå Ollama: Falhou")
            
        if results["openai"]["success"]:
            print(f"‚òÅÔ∏è OpenAI: {results['openai']['time']:.2f}s")
            print(f"   Resposta: {results['openai']['response']}")
        else:
            print("‚ùå OpenAI: Falhou")
            
        await manager.cleanup()
    else:
        print("‚ùå Falha na inicializa√ß√£o")
    print("\\nüéâ Teste conclu√≠do!")

if __name__ == "__main__":
    asyncio.run(test_ollama())
"""
    
    test_path = Path("scripts/test/test_ollama.py")
    test_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(test_path, 'w') as f:
        f.write(test_script)
    
    # Torna execut√°vel
    test_path.chmod(0o755)
    print(f"‚úÖ Script de teste criado: {test_path}")

def print_usage_instructions():
    """Imprime instru√ß√µes de uso"""
    print("\n" + "=" * 50)
    print("üéâ SETUP OLLAMA CONCLU√çDO!")
    print("=" * 50)
    
    print("\nüìã COMANDOS √öTEIS:")
    print("ollama serve                    # Iniciar servi√ßo")
    print("ollama list                     # Listar modelos")
    print("ollama pull llama3.1:8b         # Baixar modelo")
    print("ollama run llama3.1:8b          # Executar modelo")
    
    print("\nüß™ TESTES:")
    print("python scripts/test/test_ollama.py")
    print("python examples/basic_usage.py --config config/g1_ollama_llm.json5")
    
    print("\nüîÑ TROCAR MODELOS:")
    print("ollama pull mistral:7b          # Baixar modelo alternativo")
    print("ollama pull llama3.1:70b        # Modelo avan√ßado (40GB)")
    
    print("\nüìä MONITORAMENTO:")
    print("ollama ps                       # Status dos modelos")
    print("ollama logs                     # Logs do servi√ßo")
    
    print("\nüöÄ PR√ìXIMO PASSO:")
    print("Conectar DJI Mic 2 e Anker Soundcore 300 via Bluetooth")
    print("Executar: python scripts/test/test_ollama.py")

def main():
    print_header()
    
    # Verifica sistema
    system_type = check_system()
    
    # Instala Ollama
    if not install_ollama(system_type):
        print("‚ùå Falha na instala√ß√£o do Ollama")
        return
    
    # Inicia servi√ßo
    if not start_ollama_service():
        print("‚ùå Falha ao iniciar servi√ßo")
        return
    
    # Baixa modelos
    download_models()
    
    # Cria arquivos de configura√ß√£o
    create_config_files()
    
    # Cria script de teste
    create_test_script()
    
    # Instru√ß√µes finais
    print_usage_instructions()

if __name__ == "__main__":
    main()
