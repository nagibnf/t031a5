#!/usr/bin/env python3
"""ğŸ¤– TESTE SISTEMA CONVERSAÃ‡ÃƒO - ARQUIVO ÃšNICO PRINCIPAL
Teste completo: DJI Mic â†’ Google STT â†’ LLM â†’ ElevenLabs TTS â†’ Anker + G1 Movimentos
"""

import sys
import asyncio
import logging
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent / "src"))
sys.path.insert(0, "/home/unitree/t031a5/src")

# Configurar logging mais limpo
logging.basicConfig(level=logging.ERROR)

print('ğŸ¤– TESTE DE CONVERSAÃ‡ÃƒO INTERATIVA')
print('='*60)
print('ğŸ¯ OBJETIVO: Validar fluxo completo DJI â†’ Google STT â†’ LLM â†’ ElevenLabs TTS â†’ Anker + G1')
print('ğŸ“‹ INSTRUÃ‡Ã•ES: Fale CLARAMENTE no DJI Mic quando solicitado')
print('='*60)

async def reproduzir_audio_async(audio_mgr, audio_data):
    """Reproduz Ã¡udio de forma assÃ­ncrona."""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(
        None, 
        audio_mgr.reproduzir_audio_anker,
        audio_data
    )

async def executar_movimento_g1(g1_client, movement_library, movimento, duracao):
    """Executa movimento G1 com duraÃ§Ã£o especÃ­fica."""
    try:
        # Obter ID da aÃ§Ã£o
        action_id = movement_library.get_action_id(movimento)
        
        if action_id is not None:
            print(f'ğŸ¦¾ Movimento fÃ­sico: {movimento} (ID: {action_id})')
            
            # Executar movimento
            g1_client.ExecuteAction(action_id)
            
            # Aguardar duraÃ§Ã£o ou duraÃ§Ã£o do movimento
            movimento_duracao = movement_library.get_duration(movimento)
            tempo_espera = min(duracao, movimento_duracao)
            
            await asyncio.sleep(tempo_espera)
            
            # Retornar Ã  posiÃ§Ã£o neutra se necessÃ¡rio
            if tempo_espera >= movimento_duracao:
                release_id = movement_library.get_action_id("release_arm")
                if release_id:
                    g1_client.ExecuteAction(release_id)
                    print('ğŸ”„ Retornando Ã  posiÃ§Ã£o neutra')
            
        else:
            print(f'âš ï¸ Movimento "{movimento}" nÃ£o encontrado na biblioteca')
            
    except Exception as e:
        print(f'âŒ Erro no movimento G1: {e}')

async def aguardar_fala_real(audio_mgr, max_tentativas=5):
    """Aguarda captura de Ã¡udio com fala real."""
    
    for tentativa in range(1, max_tentativas + 1):
        print(f'\nğŸ¤ TENTATIVA {tentativa}/{max_tentativas}')
        print('ğŸ—£ï¸ FALE CLARAMENTE NO DJI MIC!')
        print('ğŸ’¡ Exemplo: "OlÃ¡ Tobias, como vocÃª estÃ¡?"')
        
        # Contagem regressiva
        for i in range(5, 0, -1):
            print(f'â° Iniciando em {i}s...')
            await asyncio.sleep(1)
        
        print('ğŸ”´ GRAVANDO (5s) - FALE AGORA!')
        audio_data = audio_mgr.capturar_audio_dji(5.0)
        
        if audio_data is None:
            print('âŒ Falha na captura - tentando novamente...')
            continue
        
        # Analisar qualidade
        metricas = audio_mgr.obter_metricas_audio(audio_data)
        rms = metricas.get("rms", 0)
        peak = metricas.get("peak", 0)
        
        print(f'ğŸ“Š AnÃ¡lise: RMS={rms:.4f}, Peak={peak:.4f}')
        
        # CritÃ©rios mais flexÃ­veis para fala
        if rms > 0.008 and peak > 0.05:  # Thresholds mais baixos
            print('âœ… ÃUDIO COM FALA DETECTADO!')
            return audio_data
        elif rms > 0.003:
            print('âš ï¸ Ãudio muito baixo - fale mais alto!')
        else:
            print('âŒ Apenas silÃªncio/ruÃ­do - tente novamente!')
    
    print('âŒ NÃ£o foi possÃ­vel capturar fala apÃ³s vÃ¡rias tentativas')
    return None

async def teste_conversacao_completa():
    """Teste conversacional completo com G1 movimentos."""
    
    try:
        # Importar e inicializar
        print('ğŸ“¦ Inicializando componentes...')
        from t031a5.audio.audio_manager_definitivo import AudioManagerDefinitivo
        from t031a5.speech.stt_real_manager import STTRealManager
        from t031a5.llm.llm_real_manager import LLMRealManager
        from t031a5.speech.tts_real_manager import TTSRealManager
        from t031a5.actions.g1_movement_mapping import G1MovementLibrary
        
        # Inicializar G1 SDK para movimentos
        g1_client = None
        movement_library = None
        try:
            from unitree_sdk2py.core.channel import ChannelFactoryInitialize
            from unitree_sdk2py.g1.arm.g1_arm_action_client import G1ArmActionClient as ArmActionClient
            
            ChannelFactoryInitialize(0, "eth0")
            g1_client = ArmActionClient()
            g1_client.SetTimeout(10.0)
            g1_client.Init()
            movement_library = G1MovementLibrary()
            print('âœ… G1 SDK inicializado para movimentos')
        except Exception as e:
            print(f'âš ï¸ G1 SDK nÃ£o disponÃ­vel: {e}')
        
        audio_mgr = AudioManagerDefinitivo(auto_connect_anker=True)
        stt_mgr = STTRealManager()
        llm_mgr = LLMRealManager()
        tts_mgr = TTSRealManager()
        
        # Verificar componentes
        stt_status = stt_mgr.get_status()
        if not stt_status["google_ready"]:
            print('âŒ Google STT nÃ£o estÃ¡ pronto!')
            return
        
        print('âœ… Todos os componentes inicializados')
        print(f'   ğŸ¤ Google STT: {stt_status["google_ready"]}')
        print(f'   ğŸ”Š gTTS: {tts_mgr.get_status()["providers_available"]["gtts"]}')
        
        # Loop de conversaÃ§Ã£o
        for ciclo in range(1, 4):  # AtÃ© 3 tentativas
            print('\n' + '='*50)
            print(f'ğŸ”„ CICLO CONVERSACIONAL {ciclo}/3')
            print('='*50)
            
            # 1. Capturar fala real
            audio_data = await aguardar_fala_real(audio_mgr)
            if audio_data is None:
                print('âŒ Pulando ciclo - sem fala detectada')
                continue
            
            # 2. Speech-to-Text
            print('\nğŸ¤ Processando STT (Google Speech)...')
            texto = await stt_mgr.transcribe_audio(audio_data)
            
            if not texto:
                print('âŒ STT nÃ£o conseguiu reconhecer fala')
                print('ğŸ’¡ Tente falar mais claramente em portuguÃªs')
                continue
            
            print(f'ğŸ“ RECONHECIDO: "{texto}"')
            
            # Verificar comando de saÃ­da
            if any(cmd in texto.lower() for cmd in ['tchau', 'sair', 'parar']):
                print('ğŸ‘‹ Comando de saÃ­da detectado!')
                break
            
            # 3. LLM Processing
            print('ğŸ¤– Gerando resposta...')
            resposta_llm = await llm_mgr.generate_response(texto)
            
            if not resposta_llm:
                print('âŒ LLM falhou - usando resposta padrÃ£o')
                resposta_llm = {
                    "text": "Desculpe, nÃ£o consegui processar sua mensagem.",
                    "movement": "shake_head"
                }
            
            print(f'ğŸ¤– TOBIAS: "{resposta_llm["text"]}"')
            print(f'   ğŸ¦¾ Movimento: {resposta_llm["movement"]}')
            
            # 4. Text-to-Speech
            print('ğŸ”Š Sintetizando voz...')
            audio_resposta = await tts_mgr.synthesize_speech(resposta_llm["text"])
            
            if audio_resposta is not None:
                print('ğŸ“¢ Reproduzindo via Anker...')
                
                # Executar movimento + fala sincronizados
                duracao_audio = len(audio_resposta) / 16000  # duraÃ§Ã£o em segundos
                
                # Iniciar movimento
                movimento_task = None
                if g1_client and movement_library:
                    movimento_task = asyncio.create_task(
                        executar_movimento_g1(g1_client, movement_library, resposta_llm["movement"], duracao_audio)
                    )
                    print(f'ğŸ¦¾ Executando movimento: {resposta_llm["movement"]}')
                
                # Reproduzir Ã¡udio
                audio_task = asyncio.create_task(
                    reproduzir_audio_async(audio_mgr, audio_resposta)
                )
                
                # Aguardar ambos
                if movimento_task:
                    await asyncio.gather(audio_task, movimento_task)
                else:
                    await audio_task
                
                print('âœ… CICLO CONVERSACIONAL COMPLETO!')
            else:
                print('âŒ Falha na sÃ­ntese de voz')
            
            print('\nâ³ Aguardando 3s antes do prÃ³ximo ciclo...')
            await asyncio.sleep(3)
        
        print('\nğŸ¯ TESTE CONVERSACIONAL FINALIZADO!')
        print('ğŸ‰ PARABÃ‰NS! Sistema funcionando end-to-end!')
        
    except KeyboardInterrupt:
        print('\nğŸ›‘ Teste interrompido pelo usuÃ¡rio')
    except Exception as e:
        print(f'âŒ Erro crÃ­tico: {e}')
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(teste_conversacao_completa())
