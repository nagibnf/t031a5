#!/usr/bin/env python3
"""
ðŸŽ¤ STT REAL MANAGER - Google Speech API + Whisper Fallback
Sistema de Speech-to-Text com mÃºltiplos providers para mÃ¡xima confiabilidade
"""

import os
import json
import logging
import tempfile
import wave
import numpy as np
from typing import Optional, Dict, Any
from pathlib import Path
import asyncio

# Carregar variÃ¡veis do .env
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # dotenv Ã© opcional

# Google Speech API
try:
    from google.cloud import speech
    GOOGLE_SPEECH_AVAILABLE = True
except ImportError:
    GOOGLE_SPEECH_AVAILABLE = False
    speech = None

# OpenAI Whisper
try:
    import openai
    OPENAI_WHISPER_AVAILABLE = True
except ImportError:
    OPENAI_WHISPER_AVAILABLE = False
    openai = None

# Whisper local (opcional)
try:
    import whisper
    WHISPER_LOCAL_AVAILABLE = True
except ImportError:
    WHISPER_LOCAL_AVAILABLE = False
    whisper = None

logger = logging.getLogger(__name__)

class STTRealManager:
    """
    Gerenciador de Speech-to-Text real com mÃºltiplos providers.
    
    Ordem de prioridade:
    1. Google Speech API (cloud, alta precisÃ£o)
    2. OpenAI Whisper API (cloud, fallback)
    3. Whisper Local (offline, Ãºltimo recurso)
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Inicializa STT Manager.
        
        Args:
            config: ConfiguraÃ§Ãµes customizadas
        """
        self.config = config or {}
        
        # ConfiguraÃ§Ãµes padrÃ£o
        self.language = self.config.get("language", "pt-BR")
        self.sample_rate = self.config.get("sample_rate", 16000)
        self.encoding = self.config.get("encoding", "LINEAR16")
        
        # ConfiguraÃ§Ãµes de qualidade
        self.min_confidence = self.config.get("min_confidence", 0.7)
        self.max_retries = self.config.get("max_retries", 2)
        
        # Providers disponÃ­veis
        self.providers_available = {
            "google": GOOGLE_SPEECH_AVAILABLE,
            "openai_whisper": OPENAI_WHISPER_AVAILABLE,
            "whisper_local": WHISPER_LOCAL_AVAILABLE
        }
        
        # Inicializar providers
        self._init_google_speech()
        self._init_openai_whisper()
        self._init_whisper_local()
        
        logger.info("ðŸŽ¤ STT Real Manager inicializado")
        self._log_providers_status()
    
    def _init_google_speech(self):
        """Inicializa Google Speech API."""
        self.google_client = None
        
        if not GOOGLE_SPEECH_AVAILABLE:
            logger.warning("âš ï¸ Google Speech API nÃ£o disponÃ­vel (google-cloud-speech nÃ£o instalado)")
            return
        
        try:
            # Verificar credenciais
            google_creds = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
            if not google_creds:
                # Tentar criar credenciais do .env
                self._setup_google_credentials()
            
            # Criar cliente
            self.google_client = speech.SpeechClient()
            
            # ConfiguraÃ§Ã£o de reconhecimento
            self.google_config = speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=self.sample_rate,
                language_code=self.language,
                enable_automatic_punctuation=True,
                enable_word_confidence=True,
                model="latest_long"  # Modelo otimizado para conversaÃ§Ã£o
            )
            
            logger.info("âœ… Google Speech API configurado")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Falha na configuraÃ§Ã£o Google Speech: {e}")
            self.google_client = None
    
    def _setup_google_credentials(self):
        """Configura credenciais Google do .env."""
        try:
            # Buscar credenciais no .env
            google_creds_path = os.getenv("GOOGLE_SPEECH_CREDENTIALS_JSON")
            if google_creds_path:
                # Verificar se Ã© um caminho para arquivo ou JSON inline
                if google_creds_path.startswith("{"):
                    # Ã‰ JSON inline - criar arquivo temporÃ¡rio
                    creds_path = Path("/tmp/google_speech_credentials.json")
                    creds_path.write_text(google_creds_path)
                    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = str(creds_path)
                    logger.info("âœ… Credenciais Google configuradas do JSON inline")
                else:
                    # Ã‰ caminho para arquivo - usar diretamente
                    creds_file = Path(google_creds_path)
                    if not creds_file.is_absolute():
                        # Caminho relativo - resolver a partir do diretÃ³rio do projeto
                        project_root = Path(__file__).parent.parent.parent.parent
                        creds_file = project_root / creds_file
                    
                    if creds_file.exists():
                        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = str(creds_file)
                        logger.info(f"âœ… Credenciais Google configuradas do arquivo: {creds_file}")
                    else:
                        logger.error(f"âŒ Arquivo de credenciais nÃ£o encontrado: {creds_file}")
            else:
                logger.warning("âš ï¸ GOOGLE_SPEECH_CREDENTIALS_JSON nÃ£o encontrado no .env")
        except Exception as e:
            logger.warning(f"âš ï¸ Erro configurando credenciais Google: {e}")
    
    def _init_openai_whisper(self):
        """Inicializa OpenAI Whisper API."""
        self.openai_client = None
        
        if not OPENAI_WHISPER_AVAILABLE:
            logger.warning("âš ï¸ OpenAI Whisper nÃ£o disponÃ­vel (openai nÃ£o instalado)")
            return
        
        try:
            # Configurar API key
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                logger.warning("âš ï¸ OPENAI_API_KEY nÃ£o encontrada no .env")
                return
            
            # Criar cliente
            self.openai_client = openai.OpenAI(api_key=api_key)
            logger.info("âœ… OpenAI Whisper API configurado")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Falha na configuraÃ§Ã£o OpenAI Whisper: {e}")
            self.openai_client = None
    
    def _init_whisper_local(self):
        """Inicializa Whisper local."""
        self.whisper_model = None
        
        if not WHISPER_LOCAL_AVAILABLE:
            logger.warning("âš ï¸ Whisper local nÃ£o disponÃ­vel (whisper nÃ£o instalado)")
            return
        
        try:
            # Carregar modelo pequeno para economia de recursos
            model_name = self.config.get("whisper_model", "base")
            self.whisper_model = whisper.load_model(model_name)
            logger.info(f"âœ… Whisper local configurado (modelo: {model_name})")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Falha na configuraÃ§Ã£o Whisper local: {e}")
            self.whisper_model = None
    
    def _log_providers_status(self):
        """Log status dos providers."""
        logger.info("ðŸ“Š STATUS PROVIDERS STT:")
        for provider, available in self.providers_available.items():
            status = "âœ… DisponÃ­vel" if available else "âŒ IndisponÃ­vel"
            logger.info(f"   {provider}: {status}")
    
    async def transcribe_audio(self, audio_data: np.ndarray) -> Optional[str]:
        """
        Transcreve Ã¡udio para texto usando o melhor provider disponÃ­vel.
        
        Args:
            audio_data: Dados de Ã¡udio (mono, 16kHz, float32)
            
        Returns:
            str: Texto transcrito ou None se falha
        """
        if audio_data is None or len(audio_data) == 0:
            logger.error("âŒ Dados de Ã¡udio invÃ¡lidos")
            return None
        
        # Tentar providers em ordem de prioridade
        providers = [
            ("google", self._transcribe_google),
            ("openai_whisper", self._transcribe_openai_whisper),
            ("whisper_local", self._transcribe_whisper_local)
        ]
        
        for provider_name, transcribe_func in providers:
            if not self.providers_available[provider_name]:
                continue
            
            try:
                logger.info(f"ðŸŽ¤ Tentando STT via {provider_name}...")
                
                # Tentar transcriÃ§Ã£o
                resultado = await transcribe_func(audio_data)
                
                if resultado and len(resultado.strip()) > 0:
                    logger.info(f"âœ… STT sucesso via {provider_name}: '{resultado}'")
                    return resultado.strip()
                else:
                    logger.warning(f"âš ï¸ {provider_name} retornou resultado vazio")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ Falha STT {provider_name}: {e}")
                continue
        
        logger.error("âŒ Todos os providers STT falharam")
        return None
    
    async def _transcribe_google(self, audio_data: np.ndarray) -> Optional[str]:
        """TranscriÃ§Ã£o via Google Speech API."""
        if not self.google_client:
            raise Exception("Google Speech client nÃ£o inicializado")
        
        # Converter para formato esperado pelo Google
        audio_bytes = self._audio_to_bytes(audio_data)
        
        # Criar objeto de Ã¡udio
        audio = speech.RecognitionAudio(content=audio_bytes)
        
        # Executar reconhecimento
        response = self.google_client.recognize(
            config=self.google_config,
            audio=audio
        )
        
        # Processar resultado
        if response.results:
            # Pegar melhor resultado
            result = response.results[0]
            if result.alternatives:
                alternative = result.alternatives[0]
                
                # Verificar confianÃ§a
                confidence = getattr(alternative, 'confidence', 1.0)
                if confidence >= self.min_confidence:
                    return alternative.transcript
                else:
                    logger.warning(f"âš ï¸ ConfianÃ§a baixa Google Speech: {confidence}")
        
        return None
    
    async def _transcribe_openai_whisper(self, audio_data: np.ndarray) -> Optional[str]:
        """TranscriÃ§Ã£o via OpenAI Whisper API."""
        if not self.openai_client:
            raise Exception("OpenAI client nÃ£o inicializado")
        
        # Salvar Ã¡udio como arquivo temporÃ¡rio
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
            self._save_audio_wav(audio_data, temp_file.name)
            
            try:
                # Fazer upload e transcriÃ§Ã£o
                with open(temp_file.name, "rb") as audio_file:
                    response = self.openai_client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio_file,
                        language="pt"  # PortuguÃªs
                    )
                
                return response.text
                
            finally:
                # Limpeza
                Path(temp_file.name).unlink()
    
    async def _transcribe_whisper_local(self, audio_data: np.ndarray) -> Optional[str]:
        """TranscriÃ§Ã£o via Whisper local."""
        if not self.whisper_model:
            raise Exception("Whisper local nÃ£o inicializado")
        
        # Salvar Ã¡udio temporÃ¡rio
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
            self._save_audio_wav(audio_data, temp_file.name)
            
            try:
                # Transcrever
                result = self.whisper_model.transcribe(
                    temp_file.name,
                    language="pt"
                )
                
                return result["text"]
                
            finally:
                # Limpeza
                Path(temp_file.name).unlink()
    
    def _audio_to_bytes(self, audio_data: np.ndarray) -> bytes:
        """Converte Ã¡udio para bytes (16-bit)."""
        # Converter float32 â†’ int16
        audio_int16 = (audio_data * 32767).astype(np.int16)
        return audio_int16.tobytes()
    
    def _save_audio_wav(self, audio_data: np.ndarray, filename: str):
        """Salva Ã¡udio como arquivo WAV."""
        audio_int16 = (audio_data * 32767).astype(np.int16)
        
        with wave.open(filename, 'wb') as wav_file:
            wav_file.setnchannels(1)  # Mono
            wav_file.setsampwidth(2)  # 16-bit
            wav_file.setframerate(self.sample_rate)
            wav_file.writeframes(audio_int16.tobytes())
    
    def get_status(self) -> Dict[str, Any]:
        """ObtÃ©m status detalhado do STT Manager."""
        return {
            "providers_available": self.providers_available.copy(),
            "google_ready": self.google_client is not None,
            "openai_ready": self.openai_client is not None,
            "whisper_local_ready": self.whisper_model is not None,
            "language": self.language,
            "sample_rate": self.sample_rate,
            "min_confidence": self.min_confidence
        }

# Exemplo de uso
if __name__ == "__main__":
    import asyncio
    import logging
    
    logging.basicConfig(level=logging.INFO)
    
    async def test_stt():
        """Teste bÃ¡sico do STT."""
        stt_manager = STTRealManager()
        
        # Status
        status = stt_manager.get_status()
        print("ðŸ“Š STATUS STT:")
        for key, value in status.items():
            print(f"   {key}: {value}")
        
        # Simular Ã¡udio (seria do AudioManagerDefinitivo)
        # audio_data = audio_manager.capturar_audio_dji(5.0)
        # texto = await stt_manager.transcribe_audio(audio_data)
        
        print("âœ… STT Manager testado")
    
    asyncio.run(test_stt())
